<html>
	<head>
		<meta http-equiv="Content-Type" content="text/html; charset=ks_c_5601-1987">
		<link href="./default.css" type="text/css" rel="stylesheet">
		<script type="text/javascript" src="./default.js"></script>
	</head>
	
	<body class="bdstyle" onload="onBodyLoad();" onmousedown="onBodyMouseDown();">
	<!-- Page Title -->
	<div id="areafixed" class="bdstyleTitle">
		<div class="title">DQN
		<div class="version"></div>
		</div>
		<hr class="headerLine">
	</div>
	<!-- Page Title -->
	
	
	<!-- Begin Client Area -->
	<div id="areascroll" class="bdstyleBody">
		<p>
		<div class="node"><img src="./files/imagesRL/DQN0.jpg"></div>
		<div class="nodeexplain">
			<span class="nodeExHighlight">Q 학습</span>을 신경망 시스템을 기반으로 수행하여 얻어낸 출력값 중 <span class="nodeExHighlight">가장 큰 값을 가진 행동을 선택</span>하여 제어하는 <span class="nodeExHighlight">강화학습</span> 알고리즘입니다.
		</div>
		<div style="clear: both;"></div>

	</p>
	
	<hr class="nodeLine">
	
	<a href="#개요">개요</a>,
	<a href="#고려사항">고려사항</a>,
	<a href="#사용법">사용법</a>,
	<a href="#속성">속성</a>,
	<a href="#결과">결과</a>
	
	<a name="개요"><h3>개요</h3></a>

	<ul class="liType02">
		<li>
			<p>
				<span class="genExHighlight">Q 학습(Q-learning)</span>이란, 현재의 상태에서 특정 행동을 선택하여 수행하였을 때, 미래에 받게 될 것이라 기대되는 보상의 합을 예측하는 함수인 <span class="genExHighlight">Q 함수</span>를 학습하여, 최적의 정책을 학습하는 강화학습 기법입니다. 
			</p>
		</li>
		<li>
			<p>
				Q 함수는 가치함수에 <span class="genExHighlight">정책(policy)</span>의 개념을 반영한 삼수로, 여기서 정책이란, agent가 특정 <span class="genExHighlight">상태(state)</span>에서 어떤 <span class="genExHighlight">행동(action)</span>을 취할 것인지에 대한 방침입니다. 
			</p>
		</li>
		<li>
			<p>
				Q 함수를 기준으로, agent는 모든 정책(상태, 행동)들에 대한 Q 값을 가지게 됩니다. 이러한 이론을 바탕으로, Q 함수를 사용해 다음 타임 스텝의 보상을 표현할 수 있습니다.
			</p>
		</li>
			<P style="MARGIN-LEFT: 50px"><IMG src="./files/imagesRL/DQN1.png"> </P>
		<li>
			<p>
				<span class="genExHighlight">DQN</span>은 <span class="genExHighlight">SARSA(State-Action-Reward-State-Action)</span> 알고리즘을 기반으로 하여, 각 타임 스텝마다 Q 학습을 수행합니다.
			</p>
			<P style="MARGIN-LEFT: 50px"><IMG src="./files/imagesRL/DQN2.png"> </P>
			<P style="MARGIN-LEFT: 50px"><IMG src="./files/imagesRL/DQN3.png"> </P>
			<p>
				Q 함수 업데이트를 위해 <span class="genExHighlight">One Step Sample을 통하여 예측된 값과의 차이(error)</span>를 기반으로 업데이트를 수행합니다.
			</p>
			<P style="MARGIN-LEFT: 50px"><IMG src="./files/imagesRL/DQN4.png"> </P>
			<p>
				(alpha: 학습률)
			</p>
			<p>
				강화학습은 최대의 보상을 목표로 하므로, 다음 Q 함수의 최대값을 활용하여 현재의 Q 함수를 업데이트합니다.
			</p>
			<P style="MARGIN-LEFT: 50px"><IMG src="./files/imagesRL/DQN5.png"> </P>
		</li>
	</ul>

	
	<a name="고려사항"><h3>고려사항</h3></a>
	<ul class="liType02">
		<li><span class="genExHighlight">환경모델</span>이 필요합니다. </li>
		<li><span class="genExHighlight">환경모델</span>에서 사용된 <span class="genExHighlight">독립변수</span>와 <span class="genExHighlight">종속변수</span>가 필요합니다. </li>
		<li><span class="genExHighlight">독립변수</span>는 연속형/이산형의 변수 모두 사용 가능합니다. </li>
		
		<li><span class="genExHighlight">제어변수</span>는 이산형이어야 합니다.</li>
	</ul>

	<a name="사용법"><h3>사용법</h3></a>
	<ul class="liType02">
		<li><span class="genExHighlight">입력노드</span>를 통해 데이터를 읽어들입니다.</li>
		<li><span class="genExHighlight">DQN 노드</span>를 <span class="genExHighlight">입력노드</span>에 연결하고 옵션들을 선택합니다.</li>
		<li><span class="genExHighlight">화면표시 노드</span>를 <span class="genExHighlight">DQN 노드</span>에 연결합니다.</li>
		<p>
			<img src="./files/imagesRL/DQN6.jpg">
		</p>		
	</ul>
		
		
	<a name="속성"><h3>속성</h3></a>
		<table class="tbStyle01">
			<thead>
				<tr>
					<th width="60">속성그룹</th>
					<th width="100">속성명</th>
					<th width="">설명</th>
					<th width="60">기타</th>
					<th width="60">비고</th>
				</tr>
			</thead>
			
				<tr>
					<th rowspan="2">일반정보</th>
					<td>이름</td>
					<td>노드의 이름을 입력합니다.</td>
					<td>선택</td>
					<td></td>
				</tr>
				<tr>
					<td>설명</td>
					<td>노드에 대한 간단한 주석을 달 수 있습니다.</td>
					<td>선택</td>
					<td></td>
				</tr>
				<tr>
					<th rowspan="2">모델파일</th>
					<td>모델파일 생성</td>
					<td>모델링 후에 모델 파일을 생성할지의 여부를 선택합니다.</td>
					<td>필수</td>
					<td>예, 아니오</td>
				</tr>
				<tr>
					<td>모델파일 경로</td>
					<td>모델 파일을 생성할시 저장할 모델 파일의 경로를 선택합니다.</td>
					<td>조건부 필수</td>
					<td></td>
				</tr>
				<tr>
					<th rowspan="19">선택사항</th>
					<td>환경모델파일 설정</td>
					<td>환경모델로 불러올 gms 파일을 선택합니다.</td>
					<td>필수</td>
					<td></td>
				</tr>
				<tr>
					<td>할인율</td>
					<td>보상에 대한 할인율을 지정합니다.</td>
					<td>필수</td>
					<td>0이상 1이하의 실수</td>
				</tr>
				<tr>
					<td>학습률</td>
					<td>인공신경망의 학습률을 설정합니다.</td>
					<td>필수</td>
					<td></td>
				</tr>
				<tr>
					<td>Epsilon</td>
					<td>행동을 랜덤으로 선택할 확률을 설정합니다. 0일 때가 Q값이 높은 행동을 선택, 1일 때가 완전한 랜덤 행동을 선택합니다.</td>
					<td>필수</td>
					<td>0이상 1이하의 실수</td>
				</tr>
				<tr>
					<td>Epsilon 감쇠율</td>
					<td>Epsilon의 감쇠율을 지정합니다.</td>
					<td>필수</td>
					<td>0이상 1이하의 실수</td>
				</tr>
				<tr>
					<td>Epsilon 최소값</td>
					<td>Epsilon의 최소값을 지정합니다.</td>
					<td>필수</td>
					<td>0이상 1이하의 실수</td>
				</tr>
				<tr>
					<td>리플레이 메모리 크기</td>
					<td>리플레이 메모리에 저장할 샘플의 최대 개수를 설정합니다.</td>
					<td>필수</td>
					<td>자연수</td>
				</tr>
				<tr>
					<td>최소 학습 시작 크기</td>
					<td>학습 시작을 위한 리플레이 메모리의 최소 크기를 지정합니다.</td>
					<td>필수</td>
					<td>리플레이 메모리 크기보다 작거나 같은 값.</td>
				</tr>
				<tr>
					<td>배치 크기</td>
					<td>학습을 위해 메모리에서 추출 할 샘플 배치 개수를 입력합니다.</td>
					<td>필수</td>
					<td>자연수</td>
				</tr>
				<tr>
					<td>최대 에피소드</td>
					<td>학습할 최대 에피소드 횟수를 지정합니다.</td>
					<td>필수</td>
					<td>자연수</td>
				</tr>
				<tr>
					<td>최대 스텝</td>
					<td>한 에피소드에서 최대 스텝 횟수를 지정합니다.</td>
					<td>필수</td>
					<td>자연수</td>
				</tr>	
				<tr>
					<td>제어 Target 변수 선택</td>
					<td>제어 대상 변수에 대한 Target 값을 가지고 있는 변수를 지정합니다.</td>
					<td>필수</td>
					<td>이상형 변수</td>
				</tr>			
				<tr>
					<td>목표치 허용오차</td>
					<td>환경 보상 정의를 위한 Target 값에 대한 허용오차를 입력합니다.</td>
					<td>필수</td>
					<td>자연수</td>
				</tr>			
				<tr>
					<td>목표치 관리 상한</td>
					<td>에피소드 종료 조건을 지정합니다. 환경모델에서 Y-Hat의 값이 이 값보다 클 때 에피소드가 종료됩니다.</td>
					<td>필수</td>
					<td></td>
				</tr>	
				<tr>
					<td>목표치 관리 하한</td>
					<td>에피소드 종료 조건을 지정합니다. 환경모델에서 Y-Hat의 값이 이 값보다 작을 때 에피소드가 종료됩니다.</td>
					<td>필수</td>
					<td>자연수</td>
				</tr>				
				<tr>
					<td>제어변수 선택</td>
					<td>환경모델 제어변수를 지정합니다.</td>
					<td>필수</td>
					<td></td>
				</tr>				
				<tr>
					<td>제어량</td>
					<td>조절 변수의 제어량을 지정합니다.</td>
					<td>필수</td>
					<td></td>
				</tr>				
				<tr>
					<td>배치정규화 여부</td>
					<td>배치정규화 사용 여부를 결정합니다.</td>
					<td>필수</td>
					<td>예, 아니오</td>
				</tr>				
				<tr>
					<td>출력층 활성함수</td>
					<td>출력층의 활성함수를 지정합니다.</td>
					<td>필수</td>
					<td>Linear, Sigmoid, ReLU, Leaky ReLU, SoftMax</td>
				</tr>			
				<tr>
				<th rowspan="2">은닉층 설정</th>
					<td>은닉층 추가</td>
					<td>은닉층을 추가합니다.</td>
					<td>선택</td>
					<td></td>
				</tr>				<tr>
					<td>마지막 은닉층 제거</td>
					<td>마지막 은닉층을 제거합니다.</td>
					<td>선택</td>
					<td></td>
				</tr>		
				<tr>
				<th rowspan="2">추가된 은닉층</th>
					<td>노드개수</td>
					<td>해당하는 은닉층을 노드개수를 입력합니다.</td>
					<td>필수</td>
					<td></td>
				</tr>	
				<tr>
					<td>활성함수</td>
					<td>해당하는 은닉층의 활성함수를 선택합니다.</td>
					<td>필수</td>
					<td>Linear, Sigmoid, ReLU, Leaky ReLU, SoftMax</td>
				</tr>					
		</table>


		<h3><a name="결과">결과</a></h3>
		<ul class="liType02">
			<li>분석결과정보</li>
			<p><span class="genExHighlight">화면표시 노드</span>에서 생성된 결과 변수를 확인할 수 있습니다.</p>
			<p>
				<img src="./files/imagesRL/DQN7.jpg">
			</p>
			<br>
		</ul>
		
		<hr class="footerLine">
		<p class="footer">
	</div>
	</body>
</html>