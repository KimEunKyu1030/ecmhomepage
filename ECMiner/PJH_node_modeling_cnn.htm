<html>
	<head>
		<meta http-equiv="Content-Type" content="text/html; charset=ks_c_5601-1987">
		<link href="./default.css" type="text/css" rel="stylesheet">
		<script type="text/javascript" src="./default.js"></script>
	</head>
	
	<body class="bdstyle" onload="onBodyLoad();" onmousedown="onBodyMouseDown();">
	  <!-- Page Title -->
	  <div id="areafixed" class="bdstyleTitle">
	    <div class="title">CNN
	    <div class="version"></div>
	    </div>
	    <hr class="headerLine">
  	</div>
    <!-- Page Title -->
    
    
    <!-- Begin Client Area -->
    <div id="areascroll" class="bdstyleBody">
	    <p>
    	<div class="node"><img src="./images/node_modeling_cnn.png"></div>
    	<div class="nodeexplain">
			동물 시각 피질의 조직과 뉴런 간 연결 패턴의 유사성에서 영감을 받아 고안된 합성곱 신경망(CNN, Convolutional Neural Network)을 이용하여 2차원 이미지 데이터의 분류 작업을 수행합니다.
    	</div>
    	<div style="clear: both;"></div>

    </p>
    
    <hr class="nodeLine">
    
    <a href="#개요">개요</a>,
    <a href="#고려사항">고려사항</a>,
    <a href="#사용법">사용법</a>,
    <a href="#속성">속성</a>,
    <a href="#결과">결과</a>
		
	
    <a name="개요"><h3>개요</h3></a>

    <ul class="liType02">
		<li><span class="genExHighlight">합성곱 신경망(CNN, Convolutional Neural Network)</span>은 뉴런 사이의 연결 패턴이 동물 시각 피질의 조직과 유사하다는 점에 영감을 얻은 machine learning 방법론입니다. <span class="genExHighlight">필터(filter, 또는 커널(kernel))</span> 최적화를 통하여 자체적으로 이미지의 <span class="genExHighlight">특성들(features)</span>을 학습하는 feed-forward 신경망 구조로, 다양한 분야에서 2차원 데이터(영상 및 이미지 등)의 특성 추출 및 분류에 사용됩니다.</li>
		<br><p><img src="./files/CNN.files/CNN_LeNet-5.png" , style='height: 431px; width: 1222px;> object-fit: contain'></p><br>
		<li>합성곱 신경망은 3가지 종류의 <span class="genExHighlight">계층(layers)</span>으로 구성됩니다. <span class="genExHighlight">합성곱층(convolutional layer)</span>은 합성곱 신경망의 가장 중요한 특성으로, 이전 층의 특성 지도(feature map)에 대하여 필터(filters for convolution)를 이용한 <span class="genExHighlight">합성곱 연산(convolve)</span>를 수행하여, 이전보다 크기(size)가 작고 깊이(depth)가 깊은 특성 지도(feature map)를 생성합니다. <span class="genExHighlight">풀링층(pooling layer, 또는 sub-sampling layer)</span>은 연산량 최적화 및 과적합(overfitting) 방지를 위하여 <span class="genExHighlight">down sampling</span> 을 수행함으로써 가중치(weights) 파라미터의 개수를 줄이는 역할을 수행합니다. 완전연결층(fully connected layer, 또는 classification layer)은 합성곱층 및 풀링층을 거치며 최종적으로 추출된 특성 지도를 이용하여 분류하는 역할을 수행합니다. 완전연결층의 마지막 계층, 즉 합성곱 신경망의 마지막 계층에서 얻어지는 특성 지도는 분류하고자 하는 클래스(classes) 별 입력 데이터의 분류 확률 지도(probability map)가 됩니다. 분류 확률 지도에서 가장 높은 확률(probability, 또는 score)에 해당하는 클래스가 해당 입력 이미지의 분류 결과가 됩니다.</li>
		<br><p><img src="./files/CNN.files/CNN_Layers.png", style='height: 574px; width: 1162px; object-fit: contain'></p><br>
		<li><span class="genExHighlight">스트라이드(stride)</span>는 입력 특성 지도에서 필터 적용 시 위치 간격을 의미합니다. 합성곱 신경망의 종류(LeNet, AlexNet, VGGNet) 및 계층별로 설정 값이 고정되어 있어 수정할 수 없습니다.</li>
		<br><p><img src="./files/CNN.files/CNN_Stride.png", style='height: 600px; width: 780px; object-fit: contain'></p><br>
		<li><span class="genExHighlight">패딩(padding)</span>은 입력 특성 지도의 주위를 특정 상수 값으로 둘러싼 후 필터를 적용하는 방식을 의미합니다. 해당 값은 합성곱 신경망의 종류(LeNet, AlexNet, VGGNet) 및 계층별로 설정 값이 고정되어 있어 수정할 수 없습니다. 단, 입력층을 통과하기 전의 원본 이미지에 대한 초기 패딩은 사용자 임의 설정이 가능합니다. 패딩은 입력 특성 지도의 가장자리 데이터 정보 손실을 줄이기 위하여 고안된 방법론입니다.</li>
		<br><p><img src="./files/CNN.files/CNN_Padding.png", style='height: 400px; width: 800px; object-fit: contain'></p><br>
		<li>합성곱 신경망은 2차원 이미지 분류에 특화된 인공신경망의 일종입니다. 기본적으로 인공신경망의 학습 과정은 <span class="genExHighlight">최적의 가중치 조합</span>을 찾아내는 과정입니다.</li>
		<li>합성곱 신경망 또한 대부분의 인공신경망 구조들과 마찬가지로 최적화를 진행하기 위해 <span class="genExHighlight">gradient descent (경사하강법)</span> 기반 알고리즘을 사용합니다.</li>
		<br><p><img src="./files/DNN.files/DNN_Gradient.png", style='height: 200px; width: 700px; object-fit: contain'></p><br>
		<li>W 는 인공신경망의 모든 가중치 와 bias 를 원소로 하는 값 배열, C(W) 는 최소화를 할 대상이 되는 손실함수, ∇_W F(W) 는 W에 대한 함수 F(W)의 gradient, α 는 학습 계수</li>
		<li>정리해보면 가중치 W는 gradient 반대 방향으로 이동하여야 하고, gradient의 크기에 비례하여 이동하여야 합니다.</li>
 </li>
  	</ul>
  	
  	<a name="고려사항"><h3>고려사항</h3></a>
    <ul class="liType02">
		<li>노드 속성창의 <span class="genExHighlight">입력 이미지 경로 변수</span>에 원본 이미지 위치 정보를 가지는 문자열 변수가 선택되어 있어야 합니다.</li>
		<li>라벨링 정보를 가지는 문자열 변수가 <span class="genExHighlight">종속변수</span>로 설정되어 있어야 합니다.</li>
  	</ul>
  	
  	<a name="사용법"><h3>사용법</h3></a>
    <ul class="liType02">
  		<li><span class="genExHighlight">이미지 입력 노드</span>를 통해 이미지 데이터를 읽어들입니다.</li>
  		<li>여러 <span class="genExHighlight">전처리 노드</span>들(필터, 파생변수 등)을 조합하여 원본 이미지 경로에서 라벨링 정보를 추출하는 등의 방법을 사용하여 라벨링을 수행하고, 해당 정보를 저장하는 문자열 형식 변수를 생성합니다.</li>
   		<li><span class="genExHighlight">형태변경 노드</span>를 이용하여 라벨링 결과 정보가 저장된 <span class="genExHighlight">문자열 형식 변수를 종속변수</span>로 설정합니다.</li>
  		<li><span class="genExHighlight">CNN 노드</span> 속성창의 <span class="genExHighlight">입력 이미지 경로 변수</span> 항목에서 입력 이미지들의 위치 정보를 가지는 문자열 형식 변수를 선택합니다.</li>
  		<li><span class="genExHighlight">화면표시 노드</span>를 <span class="genExHighlight">CNN 노드</span>에 연결합니다. </li>
		<li><span class="genExHighlight">CNN diagram</span> 예시는 아래와 같습니다.</li>
  		<p>			
    	<img src="./files/CNN.files/CNN_diagram.png">
  		</p>
  	</ul>
			
		
    <a name="속성"><h3>속성</h3></a>
		<table class="tbStyle01">
			<thead>
				<tr>
					<th width="60">속성그룹</th>
					<th width="100">속성명</th>
					<th width="">설명</th>
					<th width="100">기타</th>
					<th width="60">비고</th>
				</tr>
			</thead>
			
				<tr>
					<th rowspan="2">일반정보</th>
					<td>이름</td>
					<td>노드의 이름을 입력합니다.</td>
					<td>선택</td>
					<td></td>
				</tr>
				<tr>
					<td>설명</td>
					<td>노드에 대한 간단한 주석을 달 수 있습니다.</td>
					<td>선택</td>
					<td></td>
				</tr>
				<tr>
					<th rowspan="2">모델파일</th>
					<td>모델파일 생성</td>
					<td>모델링 후에 모델 파일을 생성할지의 여부를 선택합니다.</td>
					<td>필수</td>
					<td>예, 아니오</td>
				</tr>
				<tr>
					<td>모델파일 경로</td>
					<td>모델 파일을 생성할시 저장할 모델 파일의 경로를 선택합니다.</td>
					<td>조건부 필수</td>
					<td></td>
				</tr>
				<tr>
					<th rowspan="17">선택사항</th>
					<td>입력 이미지 경로 변수</td>
					<td>입력 이미지 원본 경로 정보를 가지고 있는 문자열 변수를 선택합니다.</td>
					<td>필수</td>
					<td>변수명</td>
				</tr>
				<tr>
					<td>이미지 색영역</td>
					<td>입력 이미지가 컬러인지 또는 흑백인지를 선택합니다. 흑백으로 설정했다면, 입력 이미지가 컬러인 경우 흑백으로 변환하여 처리합니다.</td>
					<td>필수</td>
					<td>컬러, 흑백</td>
				</tr>
				<tr>
					<td>네트워크 종류</td>
					<td>모델링에 사용하고자 하는 합성곱 신경망 구조를 선택합니다.</td>
					<td>필수</td>
					<td>LeNet-5, AlexNet, VGGNet</td>
				</tr>
				<tr>
					<td>초기 패딩 사용</td>
					<td>입력 이미지에 초기 패딩을 적용할지 여부를 선택합니다.</td>
					<td>필수</td>
					<td>예, 아니오</td>
				</tr>
				<tr>
					<td>위쪽 패딩</td>
					<td>입력 이미지의 상단에 적용할 초기 패딩 크기를 설정합니다.</td>
					<td>조건부 필수</td>
					<td>0 이상의 정수</td>
				</tr>
				<tr>
					<td>아래쪽 패딩</td>
					<td>입력 이미지의 하단에 적용할 초기 패딩 크기를 설정합니다.</td>
					<td>조건부 필수</td>
					<td>0 이상의 정수</td>
				</tr>
				<tr>
					<td>왼쪽 패딩</td>
					<td>입력 이미지의 좌측에 적용할 초기 패딩 크기를 설정합니다.</td>
					<td>조건부 필수</td>
					<td>0 이상의 정수</td>
				</tr>
				<tr>
					<td>오른쪽 패딩</td>
					<td>입력 이미지의 우측에 적용할 초기 패딩 크기를 설정합니다.</td>
					<td>조건부 필수</td>
					<td>0 이상의 정수</td>
				</tr>
				<tr>
					<td>최적화 기법</td>
					<td>최적화 기법을 선택합니다.</td>
					<td>필수</td>
					<td>Gradient Descent with Momentum, AdaGrad, RMSProp, ADAM</td>
				</tr>
				<tr>
					<td>학습률</td>
					<td>최적화 기법 도중 가중치를 업데이트 하는 정도를 설정합니다.</td>
					<td>필수</td>
					<td>0초과 1이하의 실수</td>
				</tr>
				<tr>
					<td>모멘텀</td>
					<td>Gradient descent with momentum 최적화 기법에서 가중치가 기존에 이동하는 방향을 반영하는 정도를 설정합니다.</td>
					<td>조건부 필수</td>
					<td>0이상 1미만의 실수</td>
				</tr>
				<tr>
					<td>Gamma</td>
					<td>RMSProp 최적화 기법에서 기존에 업데이트된 가중치를 기억하는 비율을 설정합니다.</td>
					<td>조건부 필수</td>
					<td>0이상 1미만의 실수</td>
				</tr>
				<tr>
					<td>Beta1</td>
					<td>ADAM 최적화 기법에서 가중치가 기존에 이동하는 방향을 반영하는 정도를 설정합니다.</td>
					<td>조건부 필수</td>
					<td>0이상 1미만의 실수</td>
				</tr>
				<tr>
					<td>Beta2</td>
					<td>ADAM 최적화 기법에서 기존에 업데이트된 가중치를 기억하는 비율을 설정합니다.</td>
					<td>조건부 필수</td>
					<td>0이상 1미만의 실수</td>
				</tr>
				<tr>
					<td>배치 크기</td>
					<td>Mini-batch gradient descent에서 한번에 업데이트할 데이터 수를 설정합니다.</td>
					<td>필수</td>
					<td>1이상 전체 입력 데이터 수 이하의 정수</td>
				</tr>
				<tr>
					<td>학습 횟수(Epoch)</td>
					<td>학습 횟수(epoch)를 설정합니다.</td>
					<td>필수</td>
					<td>1이상 정수</td>
				</tr>
		</table>
		<ul class="liType02">
			<li><span class="genExHighlight">활성화 함수</span></li>
			<p><img src="./files/DNN.files/DNN_Activation.png", style='height: 370px; width: 800px; object-fit: contain'></p><br>
			<li><span class="genExHighlight">배치 크기</span></li>
			1)	Gradient Descent with Momentum
			움직이는 물체가 같은 방향으로 계속 움직이려 하는 관성의 법칙과 유사한 방법으로 가중치를 업데이트 합니다. 모멘텀(Momentum) 계수가 1에 가까울 수록 기존 이동 방향을 유지하려는 성향을 가지고 0에 가까울 수록 일반 gradient descent에 가까워집니다. 극단적으로 모멘텀 계수가 1인 경우는 기존의 방향을 계속 유지하면서 새로운 gradient를 추가합니다. 반대로 모멘텀 계수가 0인 경우 일반 gradient descent와 같아집니다.
			<li><span class="genExHighlight">최적화 알고리즘</span></li>
			<span class="genExHighlight">1)	Gradient Descent with Momentum</span><br>
			움직이는 물체가 같은 방향으로 계속 움직이려 하는 관성의 법칙과 유사한 방법으로 가중치를 업데이트 합니다. 모멘텀(Momentum) 계수가 1에 가까울 수록 기존 이동 방향을 유지하려는 성향을 가지고 0에 가까울 수록 일반 gradient descent에 가까워집니다. 극단적으로 모멘텀 계수가 1인 경우는 기존의 방향을 계속 유지하면서 새로운 gradient를 추가합니다. 반대로 모멘텀 계수가 0인 경우 일반 gradient descent와 같아집니다.<br>
			<span class="genExHighlight">2)	Adagrad</span><br>
			업데이트 되는 변수 중 학습 과정에서 변동이 많은 변수들에 대한 학습을 줄입니다. 예를 들어 변수 1이 매 업데이트 과정에서 10, 10, 10씩 업데이트 되었고 변수 2가 1,1,1씩 업데이트되었다고 하면 변수 1 방향으로 업데이트가 많이 된 것이므로 변수 1에대한 학습 세기를 줄입니다. 반대의 경우 학습 세기를 늘립니다.<br>
			<span class="genExHighlight">3)	RMSProp</span><br>
			Adagrad는 가변적 학습 세기를 적용하여 여러 변수에서 업데이트가 골고루 되게 하는 장점을 가지고 있지만, 업데이트시 오래 전의 gradient의 크기까지 기억하기 때문에 현재 업데이트의 학습 세기가 0에 가까워지는 문제가 발생하기도 합니다. 이를 해결하기 위한 방법이 RMSProp입니다. RMSProp은 이때까지 계산한 gradient를 모두 동등하게 반영하여 학습세기를 조절하는 것이 아니라 최근에 발생한 gradient의 중요도를 높게 반영하여 학습세기를 조절합니다. RMSProp에서 gamma 값은 개별적인 변수에 대해 기존의 gradient의 크기 기록을 저장한 값과 현재의 gradient 크기를 몇대 몇으로 반영하여 학습세기를 조절할지 결정하는 변수입니다. Gamma값이 1에 가까우면 기존의 오래된 gradient의 크기도 학습률 조절에 반영이 됩니다. 예를 들어 어떤 변수의 업데이트 시점 별 편미분 값이 {100, 0, 0}인 경우 gamma 값이 클 수록 편미분값 100을 오랫동안 기억하여 학습세기를 작게 조절합니다. 반면에 gamma 값이 작을수록 기존에 학습된 편미분 값 100을 빨리 잊어버려 학습세기를 크게 조절합니다. <br>
			<span class="genExHighlight">4)	ADAM</span><br>
			ADAM은 기존의 가중치의 이동 진행방향을 유지하는 momentum의 장점과, 학습이 많이 진행된 변수에 대한 학습세기를 줄여주는 RMSProp의 장점을 동시에 사용하기 위해 개발된 학습 방법입니다. 설정 가능한 옵션은 beta1과 beta2가 있습니다. Beta1값은 momentum 계수와 같이 1에 가까울 수록 기존의 gradient값이 이동하려는 방향성을 유지시켜줍니다. Beta2 값은 RMSProp의 gamma 값과 유사하게 현재시점 이전의 gradient의 크기를 유지하는 비율입니다Beta2 값이 1에 가까울수록, 이전 업데이트 시점에 의해 현재 시점의 학습세기가 줄어드는 영향력이 늘어납니다.<br>
		</ul>
		<a name="결과"><h3>결과</h3></a>
        <ul class="liType02">
		<li><span class="genExHighlight">메시지 창</span></li>
		메시지 창에 매 batch 마다 batch 별 분류 정확도(%)를 보여주고, 매 epoch 마다 epoch 별 mean square error와 root mean square error를 보여줍니다.
		<p><img src="./files/CNN.files/CNN_Training.png", style='height: 390px; width: 477px; object-fit: contain'></p><br>
  		<li><span class="genExHighlight">분석결과정보</span></li>			
    	<span class="genExHighlight">화면표시</span> 노드에서 분류 결과를 확인할 수 있습니다. 아래 그림은 입력 이미지 데이터에 따른 종속변수(Label)를 CNN 학습 과정을 거쳐 산출한 분류 예측 결과입니다. 변수 CNN#_YHAT은 (#는 생성된 노드에 따라 변동) 모델링 결과 최종적으로 만들어진 모델이 입력 이미지에 대하여 판단한 분류 결과 예측값입니다. 변수 CNN#_MaxOut은 최종 CNN 모델이 분류 결과 예측값(CNN#_YHAT)을 어느 정도로 확신하여 분류하였는지(분류 확률) 나타냅니다. 
		<p><img src="./files/CNN.files/CNN_Training_Result.png", style='height: 381px; width: 996px; object-fit: contain'></p><br>
  	</ul>
		
		<hr class="footerLine">
		<p class="footer">
	</div>
	</body>
</html>
