<html>
	<head>
		<meta http-equiv="Content-Type" content="text/html; charset=ks_c_5601-1987">
		<link href="./default.css" type="text/css" rel="stylesheet">
		<script type="text/javascript" src="./default.js"></script>
	</head>
	
	<body class="bdstyle" onload="onBodyLoad();" onmousedown="onBodyMouseDown();">
	  <!-- Page Title -->
	  <div id="areafixed" class="bdstyleTitle">
	    <div class="title">Policy Gradient
	    <div class="version"></div>
	    </div>
	    <hr class="headerLine">
  	</div>
    <!-- Page Title -->
    
    
    <!-- Begin Client Area -->
    <div id="areascroll" class="bdstyleBody">
	    <p>
    	<div class="node"><img src="./files/imagesRL/PG0.png"></div>
    	<div class="nodeexplain">
			기대하는 보상(reward)을 <span class="nodeExHighlight">정책(policy)</span>의 함수로 모델링하고, 보상을 최대화하는 정책을 gradient ascent 기법을 이용하여 찾아내는 기법입니다.    	</div>
    	<div style="clear: both;"></div>

    </p>
    
    <hr class="nodeLine">
    
    <a href="#개요">개요</a>,
    <a href="#고려사항">고려사항</a>,
    <a href="#사용법">사용법</a>,
    <a href="#속성">속성</a>,
    <a href="#결과">결과</a>
		
	
    <a name="개요"><h3>개요</h3></a>

    <ul class="liType02">
  		<li>Q 학습 알고리즘은 <span class="genExHighlight">환경에 대한 상태 공간이 너무 크거나 다차원인 경우</span>, 각 상태에 대한 가치 함수를 정의하는 것이 쉽지 않습니다. 또한, Q 값의 업데이트에 따라 <span class="genExHighlight">정책이 과도하게 급변</span>하는 경우가 발생할 수 있습니다.</li>
		<li>이러한 <span class="genExHighlight">value function의 취약점을 해결</span>하고자 개발된 Policy Gradient 알고리즘은, Q 함수 대신 <span class="genExHighlight">목표함수(Objective Function)</span>를 최적화하여 최대의 보상을 얻고자 합니다.</li>
                   <li><span class="genExHighlight">목표함수</span>란, 경로 동안 받을 것이라고 기대하는 보상의 합으로 정의됩니다.</li>
		<li>다음과 같은 경로가 존재할 때,</li>
     	         <p style="margin-left:50">			
    	<img src="./files/imagesRL/PG1.png">
                   <p>경로(tau)에 대한 목표함수는 다음과 같이 표현됩니다.</p>
                   <p style="margin-left:50">			
    	<img src="./files/imagesRL/PG2.png">
                   <p>정책 기반의 강화학습은 <span class="genExHighlight">목표함수가 최대값을 가지도록</span> 업데이트 하는 것이 목표이므로, <span class="genExHighlight">신경망의 변수가 목표함수의 경사를 따라 올라가도록</span> 하는 학습을 수행합니다. 이를 <span class="genExHighlight">Gradient Ascent</span>라고 합니다.</p>
                   <p style="margin-left:50">			
    	<img src="./files/imagesRL/PG3.png">
                   <p>위의 식에서 목표함수의 경사를 Policy Gradient 라고 합니다.</p>
                   <p style="margin-left:50">			
    	<img src="./files/imagesRL/PG4.png">
                   <li>수식으로 자세히 표현하면, 목표함수의 정의에서,</li>
                   <p style="margin-left:50">			
    	<img src="./files/imagesRL/PG5.png">
                   <p>위의 수식에서 보상에 감가율을 도입하면,</p>
                   <p style="margin-left:50">			
    	<img src="./files/imagesRL/PG6.png">
                   <p>위와 같이 episode 단위로 정책이 업데이트되는 Monte-Carlo 방식을 기반으로 Policy Gradient 학습을 수행합니다(Monte-Carlo Policy Gradient). 이를 REINFORCE 알고리즘이라고 합니다.</p> 
                  </p>

  	</ul>

  	
  	<a name="고려사항"><h3>고려사항</h3></a>
    <ul class="liType02">
  	  		<li><span class="genExHighlight">환경모델</span>이 필요합니다. </li>
		<li><span class="genExHighlight">환경모델</span>에서 사용된 <span class="genExHighlight">독립변수</span>와 <span class="genExHighlight">종속변수</span>가 필요합니다. </li>
		<li><span class="genExHighlight">독립변수</span>는 연속형/이산형의 변수 모두 사용 가능합니다. </li>
		  	</ul>
  	
  	<a name="사용법"><h3>사용법</h3></a>
    <ul class="liType02">
  		 <li><span class="genExHighlight">입력노드</span>를 통해 데이터를 읽어들입니다.</li>
		<li><span class="genExHighlight">Policy Gradient 노드</span>를 <span class="genExHighlight">입력노드</span>에 연결하고 옵션들을 선택합니다.</li>		
		<li><span class="genExHighlight">화면표시 노드</span>를 <span class="genExHighlight">Policy Gradients 노드</span>에 연결합니다.</li>
    		<p>			
    	<img src="./files/imagesRL/PG7.png">
  		</p>
  	</ul>
			
		
    <a name="속성"><h3>속성</h3></a>
		<table class="tbStyle01">
			<thead>
				<tr>
					<th width="60">속성그룹</th>
					<th width="100">속성명</th>
					<th width="">설명</th>
					<th width="60">기타</th>
					<th width="60">비고</th>
				</tr>
			</thead>
			
				<tr>
					<th rowspan="2">일반정보</th>
					<td>이름</td>
					<td>노드의 이름을 입력합니다.</td>
					<td>선택</td>
					<td></td>
				</tr>
				<tr>
					<td>설명</td>
					<td>노드에 대한 간단한 주석을 달 수 있습니다.</td>
					<td>선택</td>
					<td></td>
				</tr>
				<tr>
					<th rowspan="2">모델파일</th>
					<td>모델파일 생성</td>
					<td>모델링 후에 모델 파일을 생성할지의 여부를 선택합니다.</td>
					<td>필수</td>
					<td>예, 아니오</td>
				</tr>
				<tr>
					<td>모델파일 경로</td>
					<td>모델 파일을 생성할시 저장할 모델 파일의 경로를 선택합니다.</td>
					<td>조건부 필수</td>
					<td></td>
				</tr>
				<tr>
					<th rowspan="12">선택사항</th>
					<td>환경모델파일 설정</td>
					<td>환경모델로 불러올 gms 파일을 선택합니다.</td>
					<td>필수</td>
					<td></td>
				</tr>
				<tr>
					<td>할인율</td>
					<td>보상에 대한 할인율을 지정합니다.</td>
					<td>필수</td>
					<td>0이상 1이하의 실수</td>
				</tr>
				<tr>
					<td>최대 에피소드</td>
					<td>학습할 최대 에피소드 횟수를 지정합니다.</td>
					<td>필수</td>
					<td>자연수</td>
				</tr>
				<tr>
					<td>최대 스텝</td>
					<td>한 에피소드에서 최대 스텝 횟수를 지정합니다.</td>
					<td>필수</td>
					<td>자연수</td>
				</tr>	
				<tr>
					<td>제어 Target 변수 선택</td>
					<td>제어 대상 변수에 대한 Target 값을 가지고 있는 변수를 지정합니다.</td>
					<td>필수</td>
					<td>이상형 변수</td>
				</tr>			
				<tr>
					<td>목표치 허용오차</td>
					<td>환경 보상 정의를 위한 Target 값에 대한 허용오차를 입력합니다.</td>
					<td>필수</td>
					<td>자연수</td>
				</tr>			
				<tr>
					<td>목표치 관리 상한</td>
					<td>에피소드 종료 조건을 지정합니다. 환경모델에서 Y-Hat의 값이 이 값보다 클 때 에피소드가 종료됩니다.</td>
					<td>필수</td>
					<td></td>
				</tr>	
				<tr>
					<td>목표치 관리 하한</td>
					<td>에피소드 종료 조건을 지정합니다. 환경모델에서 Y-Hat의 값이 이 값보다 작을 때 에피소드가 종료됩니다.</td>
					<td>필수</td>
					<td>자연수</td>
				</tr>				
				<tr>
					<td>제어변수 선택</td>
					<td>환경모델 제어변수를 지정합니다.</td>
					<td>필수</td>
					<td></td>
				</tr>				
				<tr>
					<td>제어량</td>
					<td>조절 변수의 제어량을 지정합니다.</td>
					<td>필수</td>
					<td></td>
				</tr>				
				<tr>
					<td>배치정규화 여부</td>
					<td>배치정규화 사용 여부를 결정합니다.</td>
					<td>필수</td>
					<td>예, 아니오</td>
				</tr>				
				<tr>
					<td>출력층 활성함수</td>
					<td>출력층의 활성함수를 지정합니다.</td>
					<td>필수</td>
					<td>Linear, Sigmoid, ReLU, Leaky ReLU, SoftMax</td>
				</tr>			
				<tr>
				<th rowspan="2">은닉층 설정</th>
					<td>은닉층 추가</td>
					<td>은닉층을 추가합니다.</td>
					<td>선택</td>
					<td></td>
				</tr>				<tr>
					<td>마지막 은닉층 제거</td>
					<td>마지막 은닉층을 제거합니다.</td>
					<td>선택</td>
					<td></td>
				</tr>		
				<tr>
				<th rowspan="2">추가된 은닉층</th>
					<td>노드개수</td>
					<td>해당하는 은닉층을 노드개수를 입력합니다.</td>
					<td>필수</td>
					<td></td>
				</tr>	
				<tr>
					<td>활성함수</td>
					<td>해당하는 은닉층의 활성함수를 선택합니다.</td>
					<td>필수</td>
					<td>Linear, Sigmoid, ReLU, Leaky ReLU, SoftMax</td>
				</tr>		
		</table>


		<h3><a name="결과">결과</a></h3>
		<ul class="liType02">
			<li>분석결과정보</li>
			<p><span class="genExHighlight">화면표시 노드</span>에서 생성된 결과 변수를 확인할 수 있습니다.</p>
			<p>
				<img src="./files/imagesRL/PG8.png">
			</p>
			<br>
		</ul>
		


		
		<hr class="footerLine">
		<p class="footer">
	</div>
	</body>
</html>


